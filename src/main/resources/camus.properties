# Needed Camus properties, more cleanup to come
#
# Almost all properties have decent default properties. When in doubt, comment out the property.
#

# The job name.
camus.job.name=Camus Job

# final top-level data output directory, sub-directory will be dynamically created for each topic pulled
etl.destination.path=/user/cdnlog_parent/result/
final.result.path=/download/fastweb_vip_super/

cdnlog.edge.download.path=/download/fastweb_vip/

cdnlog.super.download.path=/download/fastweb_vip_super/

cdnlog.parent.download.path=/download/fastweb_vip_parent/

# HDFS location where you want to keep execution files, i.e. offsets, error logs, and count files
etl.execution.base.path=/user/cdnlog_parent/exec
#MR运行时，不能解析的日志，存放的目录
etl.execution.error.path=/user/cdnlog_parent/exec/error
# where completed Camus job output directories are kept, usually a sub-dir in the base.path
etl.execution.offset.path=/user/cdnlog_parent/exec/offset

kafka.whitelist.topics=cdnlog_heka2,cdnlog_c01_i02

# The Kafka brokers to connect to, format: kafka.brokers=host1:port,host2:port,host3:port
#kafka.brokers=slave224:9092,slave234:9092,slave226:9092,slave227:9092,slave228:9092,slave229:9092,slave230:9092,slave231:9092,slave232:9092,slave233:9092,slave235:9092,slave236:9092
kafka.brokers=192.168.100.60:9092,192.168.100.61:9092,192.168.100.62:9092,192.168.100.63:9092,192.168.100.64:9092,192.168.100.65:9092,192.168.100.66:9092,192.168.100.67:9092,192.168.100.68:9092,192.168.100.69:9092

mapred.map.max.attempts=2

mapreduce.job.queuename=queueA

# 1:推送；  0:不推送
domain.info.push.enable=0
domain.info.push.edge.enable=0
domain.info.push..super.enable=0
domain.info.push.parent.enable=0

domain.info.save.dir=

domain.info.push.temp.dir=

cdnlog.merge.domain.logtype=5minute
cdnlog.merge.domain.source=super
cdnlog.merge.domain.post.url=http://cdnboss.api.fastweb.com.cn/Base/cont/add_big_log
cdnlog.merge.domain.post.fcname=cdnwhbigdata
cdnlog.merge.domain.post.fckey=fastweb_whbigdata

